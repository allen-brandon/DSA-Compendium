{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Tree\n",
    "\n",
    "Please cite this if you referenced this article, and share with your friends if you found this helpful!\n",
    "\n",
    "Written by Brandon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Segment Trees  allow for O(logn) range queries and updates on an ordered collection of elements. Quick access to a copy-pastable segment tree template is essential for competitive programming.\n",
    "\n",
    "##### 1. An exact quickhand template\n",
    "\n",
    "        > If you are looking for quick code to copy-paste or analyze, go to the Template.\n",
    "\n",
    "\n",
    "##### 2. Notes on the nuances of this topic\n",
    "\n",
    "        > If you are looking to better an existing understanding, go to the Notes.\n",
    "\n",
    "\n",
    "##### 3. A Guide to this topic, with examples.\n",
    "\n",
    "        > If you are looking to learn about this topic from a place of little understanding, go to the Guide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick access to code.\n",
    "\n",
    "* Call the constructor on a sequence to build the segment tree\n",
    "\n",
    "* Call tree[i] or tree[l:r] to query an index or range respectively\n",
    "\n",
    "* Call tree[i] += x or tree[l:r] += x to add to an index or range respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#All operations are O(logn), other than constructor, which is O(n)\n",
    "class SegmentTree:\n",
    "    def __init__(self, arr):\n",
    "        self.arr = arr\n",
    "        self.n = len(arr)\n",
    "        self.tree = [0] * (2 * self.n)\n",
    "        self.lazy = [0] * (2 * self.n)\n",
    "        for i in range(self.n):\n",
    "            self.tree[self.n + i] = self.arr[i]\n",
    "        for i in range(self.n - 1, 0, -1):\n",
    "            self.tree[i] = self.tree[2 * i] + self.tree[2 * i + 1]\n",
    "    \n",
    "    #Point update\n",
    "    def pointUpdate(self, i, val):\n",
    "        i += self.n\n",
    "        self.tree[i] = val\n",
    "        while i > 1:\n",
    "            i>>=1\n",
    "            self.tree[i] = self.tree[2 * i] + self.tree[2 * i + 1]\n",
    "    \n",
    "    def update(self, l, r, val):\n",
    "        l += self.n\n",
    "        r += self.n\n",
    "        l0, r0 = l, r\n",
    "        while l <= r:\n",
    "            if l & 1:\n",
    "                self.tree[l] += val\n",
    "                l += 1\n",
    "            if r & 1 == 0:\n",
    "                self.tree[r] += val\n",
    "                r -= 1\n",
    "            l >>= 1\n",
    "            r >>= 1\n",
    "        while l0 > 1:\n",
    "            l0 >>= 1\n",
    "            self.tree[l0] = self.tree[l0 << 1] + self.tree[l0 << 1 | 1]\n",
    "        while r0 > 1:\n",
    "            r0 >>= 1\n",
    "            self.tree[r0] = self.tree[r0 << 1] + self.tree[r0 << 1 | 1]\n",
    "    \n",
    "    #Lazy propogation\n",
    "    def propogate(self, i):\n",
    "        for j in range(1, self.h):\n",
    "            k = i >> j\n",
    "            if self.lazy[k]:\n",
    "                self.tree[k << 1] += self.lazy[k]\n",
    "                self.tree[k << 1 | 1] += self.lazy[k]\n",
    "                self.lazy[k << 1] += self.lazy[k]\n",
    "                self.lazy[k << 1 | 1] += self.lazy[k]\n",
    "                self.lazy[k] = 0\n",
    "\n",
    "    def rangeUpdate(self, l, r, val):\n",
    "        l += self.n\n",
    "        r += self.n\n",
    "        l0 = l\n",
    "        r0 = r\n",
    "        while l < r:\n",
    "            if l & 1:\n",
    "                self.tree[l] += val\n",
    "                self.lazy[l] += val\n",
    "                l += 1\n",
    "            if r & 1:\n",
    "                r -= 1\n",
    "                self.tree[r] += val\n",
    "                self.lazy[r] += val\n",
    "            l >>= 1\n",
    "            r >>= 1\n",
    "        self.propogate(l0)\n",
    "        self.propogate(r0 - 1)\n",
    "    \n",
    "    #Range query\n",
    "    def query(self, l, r):\n",
    "        l += self.n\n",
    "        r += self.n\n",
    "        ans = 0\n",
    "        while l < r:\n",
    "            if l & 1:\n",
    "                ans += self.tree[l]\n",
    "                l += 1\n",
    "            if r & 1:\n",
    "                r -= 1\n",
    "                ans += self.tree[r]\n",
    "            l >>= 1\n",
    "            r >>= 1\n",
    "        return ans\n",
    "    \n",
    "\n",
    "    #Make this just print the underlying structure; not the whole tree because that's hard to read\n",
    "    #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<,\n",
    "    def __str__(self):\n",
    "        return str(self.tree)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.tree)\n",
    "    \n",
    "    def __setitem__(self, i, val):\n",
    "        if type(i) == type(1):\n",
    "            i += self.n\n",
    "        self.update(i, val)\n",
    "    \n",
    "    #Remember to add support for negative indices\n",
    "    def __getitem__(self, i):\n",
    "        match type(i):\n",
    "            case slice:\n",
    "                if i.start == None:\n",
    "                    i.start = 0\n",
    "                if i.stop == None:\n",
    "                    i.stop = self.n\n",
    "                return self.query(i.start, i.stop)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example:\n",
    "tree = SegmentTree([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "print(tree[0])\n",
    "print(tree[5])\n",
    "\n",
    "#Can query ranges with slices\n",
    "print(tree[0:5])\n",
    "print(tree[:5])\n",
    "print(tree[5:10])\n",
    "print(tree[5:])\n",
    "print(tree[0:10])\n",
    "print(tree[:])\n",
    "\n",
    "#Can add to ranges with slices as well\n",
    "tree[0:5] += 10\n",
    "tree[0:5] -= 5\n",
    "\n",
    "#Can only set values explicitly if it's one point\n",
    "tree[0] = 10\n",
    "#tree[0:5] = 10 doesn't mean anything if there isn't an external context\n",
    "\n",
    "#Step is ignored\n",
    "print(tree[0:10])\n",
    "print(tree[0:10:2])\n",
    "\n",
    "#Can set and get negative indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Segment trees are one of the most important data structures. Their place as a comprimise in time complexity between a regular array and prefix array (talked about in the introduction) may seem niche. But between these three options, it's all but the default choice of the three.\n",
    "\n",
    "This is largely because O(logn) time complexity can almost always be considered synonymous with constant time. For example, take a collection of 2^32 elements (around 10 billion elements). O(n) access takes 2^32 times longer than O(1), whereas O(1) access only takes 32 times longer. Most of the time this might as well be considered constant. In the frequent situation where both range queries and element updates are needed, the choice between an array of original elements, and a prefix array is untenable. Unless there are constant updates or constant queries (not only that, but less than 32), a segment tree is faster than an array or prefix sum. The overhead in terms of sheer code complexity, particularly when it comes to specialized queries, is the only salient drawback. This is similar to the simplicity of heaps, as opposed to the more versatile multisets.\n",
    "\n",
    "On the topic of multisets, I have long held the belief that the majority of problems that demand the use of a segment tree can be solved using a multiset. That is to say, most solutions that incorporate O(logn) range queries and updates to a structure can be rewritten to utilize O(logn) insertion/deletion in an ordered structure. While of course there many problems that require the use of a segment tree, it's often worth spending a few seconds pondering the replacement of a segment tree with a simpler, built-in data-structure.\n",
    "\n",
    "Segment trees, as with other tree structures, can be written using pointers, or using an array. Here, an array structure is implemented, primarily because the size of the segment tree is often fixed, which allows for a standardized, heap-like array representation of a tree structure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ:\n",
    "\n",
    "As segment trees are intermediate data structures, they require a baseline of knowledge that extends beyond the scope of this article. Here is a list of useful questions to ask and answer before continuing.\n",
    "\n",
    "\n",
    "* How do you implement a tree structure as an array?\n",
    "    There are multiple ways to do this. This segment tree implementation uses a heap-like structure. To see another, more versatile example of a tree structure represented in an array, look at the article on disjoint sets introduction. For a heap-like structure, we choose index 0 to represent the root, indices 1 and 2 to be its left and right children respectively, indices 3, 4, 5, and 6 to be its grandchildren, 7, 8, 9, 10, 11, 12, 13, and 14 to be the next row, and so-on. This allows us to store a value and any index, and follow the formula that for any node at index i, its children are at (i * 2)+1, and (i * 2)+2. If one of these \"child\" indices j extends beyond the length of the array (j >= n), then that child doesn't exist. This is the equivalent to a tree node containing a null pointer. For example, take the following array: [0,1,2,3,4,5,6]. If we wanted to represent this as a height balanced binary search tree in this format, we could re-order this array as follows: [3,1,5,0,2,4,6]. Now, the root is 3, with all values to the \"left\" (i.e. all nodes stemming from index 1) are strictly less, and all values to the right are strictly more. This simple rearrangement, put succinctly, allows us to execute divide and conquer algorithms on our data that would otherwise be unattainable. Note that the above re-representation of array data is *not* the formulation of a segment tree. It is simply an example of the array representation of a binary tree that heaps and segment trees use.\n",
    "    \n",
    "\n",
    "* Why is this tree representation used?\n",
    "    This format uses an array to represent a height balanced, fixed-size tree. This makes it a good fit for situations where we're electing to utilize a tree structure to represent an existing collection of flattened data, which allows us to choose its structure. This is as opposed to arbitrary tree structures, which map poorly to this tree syntax. For example, a tree with one node per level would take an array of length 2^(# of nodes) to represent. But the array above only took O(n) space to re-arrange the data, because we can choose the most useful and efficient way to re-arrange the elements into a tree.\n",
    "\n",
    "* How is a segment tree implemented, using this structure?\n",
    "    Segment trees are arranged such that each node represents a range. The root node, at tree[0], represents the range of the entire tree. Each of its children, at tree[1] and tree[2], represent ranges for each half of the tree, and their combined ranges evaluate to the range represented by the root. This pattern continues down to the leaf nodes, which each represent one element in the tree. For example, take the following array: [0,1,0,1,0,1,0,1]. A segment tree intended for range sum queries would start with a root that represents the cumulative sum of the array (4), and each of its children would be ranges of the first and second halves of the array. This would be the underlying array of the segment tree: [4,2,2,1,1,1,1,0,1,0,1,0,1,0,1]. There are (2n)-1 nodes in the tree.\n",
    "\n",
    "* What happens if the size of the initial array isn't a power of two?\n",
    "    The tree is missing its rightmost nodes, and the parents of those nodes are themselves leaf nodes. For example, take the following array: [0,1,0,1,0,1]. The array for a segment tree made for sum queries of these elements would look like this: [3,1,2,1,0,1,1,]\n",
    "\n",
    "# Time Complexities:\n",
    "\n",
    "* Creation\n",
    "    O(n) time and space. For an array of length n, the segment tree has n leaves, n//2 parents for those leaves, n//4 nodes at the next level, etc. All the way up to a single root node, at tree[0]. This sum Σ(n, n/2, n/4 ... 1) is evaluates to an array of length 2n needeed for all ranges of the segment tree.\n",
    "\n",
    "* Update\n",
    "    O(logn) time, O(1) space. This applies to both range updates and updates to single elements. This is predicated on lazy propogation, described below.\n",
    "\n",
    "* Query\n",
    "    O(logn) time, O(1) space. This applies to both range queries and single element access."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "\n",
    "Below is a detailed explanation of exactly what a Segment Tree is, as well as its related terms. This is meant to acquaint you with Segment Trees, if you're not familiar with them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two extremely common questions that get asked about graphs:\n",
    "\n",
    "* What is the shortest path between two nodes?\n",
    "* Are two nodes reachable from one another?\n",
    "\n",
    "Disjoint sets are what we use to find the answer to the second of those questions (the answer to the first being BFS/Dijkstra's algorithm). For this reason they're among the most commonly used approaches for answering questions about graphs. Among other things, disjoint sets can be used to ansewr:\n",
    "\n",
    "1. Do two nodes belong to the same component?\n",
    "2. How many components are in a graph?\n",
    "3. How many nodes belong to a given component in a graph?\n",
    "\n",
    "Disjoint sets are almost always used to describe the \"components\" of a graph. In order to talk about disjoint sets further, we need to define what a \"component\" is, along with a couple of other important terms.\n",
    "\n",
    "* Component:\n",
    "    A group of nodes that are all connected to one another, directly or indirectly.\n",
    "\n",
    "* Direct vs. Indirect connection:\n",
    "    Two nodes are directly connected if they share a direct edge. Two nodes are indirectly connected if they share edges with other directly or indirectly connected nodes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a disjoint set from the ground up.\n",
    "\n",
    "Take the following graph, in the form of an adjacency list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 5 nodes: 0, 1, 2, 3, and 4\n",
    "n = 5\n",
    "#The graph is bidirectional;\n",
    "#If adj[i] contains j, then adj[j] contains i\n",
    "adj = {0:[1,2], 1:[0], 2:[0], 3:[4], 4:[3]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that node 0 is connected to nodes 1 and 2 (and vice versa). We can also see that 3 and 4 are connected to each other.\n",
    "\n",
    "Even though node 1 and node 2 aren't directly connected, we can see that they're indirectly connected through node 0. So nodes 0, 1 and 2 are all reachable from one another. But none of them can reach nodes 3 or 4. So there are two different islands, or components, in the graph. There's nodes 0, 1 and 2, and then nodes 3 and 4. We can reason through this, but how can we find this out about much larger, more complicated graphs? This is what a disjoint set is for.\n",
    "\n",
    "Before going further into its uses, let's go over the anatomy and mechanism of a disjoint set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root array\n",
    "root = [i for i in range(n)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root array, sometimes called the parent array, is the central data structure. For every node, root[i] is the root node of the ith node. This represents that nodes i, and root[i] are connected. For example, if root[1] is 0, and root[2] is 0, then both 1 and 2 are connected to root 0 (and each other). Then, if we every want to check if two nodes are connected, we can check to see if their root is the same. If root[1] is 0, and root[2] is 0, then we know they're connected to the same node, and therefore root 1 and root 2 are connected.\n",
    "\n",
    "Initially, each index in the root array points to itself. root[0] == 0, root[1] == 1, etc. This represents the initial state, that each node exists in its own component, before any edges have been introduced. The next step is to create a way to populate and access the root array. Let's start with a simplified version of union(a, b), which is how we introduce an edge between a and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#represent an edge between a and b\n",
    "def union(a, b):\n",
    "    root[b] = a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a way to connect two nodes. If we call this union on each edge, we can create an initial root array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in adj:\n",
    "    for b in adj[a]:\n",
    "        if b > a:\n",
    "            union(a, b)\n",
    "#Root:\n",
    "#[0, 0, 0, 3, 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are two groups of nodes. The nodes connected to node 0, and nodes connected to node 3. Now it appears that we have two distinct components in this graph.\n",
    "\n",
    "There are a couple things to notice about this function. The order is arbitrary here. We could just as easily have said \"root[a] = b.\" We'll return to that later. \n",
    "\n",
    "Another thing to notice about this function is that it can create trees with a large depth. Say we change our graph above slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 connects 0 and 2, instead of 0 connecting 1 and 2\n",
    "adj = {0:[1], 1:[0, 2], 2:[1], 3:[4], 4:[3]}\n",
    "#Reset root\n",
    "root = [i for i in range(n)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now 0 and 2 are connected to 1, instead of 1 and 2 being connected to 0. If we again call union, the root array will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in adj:\n",
    "    for b in adj[a]:\n",
    "        if b > a:\n",
    "            union(a, b)\n",
    "#Root:\n",
    "#[0, 0, 1, 3, 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now node 2 leads to node 1, which leads to node 0, which leads to itself, as it's the root node of its tree of connected nodes. This isn't what we want. We want every node to point to its original root node, rather than just the node above it in the tree. This is where we need a find(a) function, in order to find and update the original root node for node a.\n",
    "\n",
    "We always want to use find(a), rather than root[a], regardless of the context. Let's say root[a] gets set to node c, but then root[c] gets changed. Even if we initially used find(a) and find(c) to set root[a] to c, now we need to call find(a) again to set root[a] to find d, since node c now points to node d instead of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fina(a): find the flag node for node a\n",
    "def find(a):\n",
    "    while root[a] != a:\n",
    "        a = root[a]\n",
    "    return a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also potentially didn't want to change anything when we call union(a, b). For example if root[a] is b, we don't want to change root[b] to be a (this would arise for example if we blindly iterated through the adjacency list of a bidirectional graph, and accounted for each edge twice). If we do this, each node is each other's root. And if we look for the root \"flag-node\" for a given node by repeatedly looking at root[a] then root[ root[a]]... etc. Then we'll enter an infinite cycle. This is solved by returning from the function early if the nodes are already connected. Now we can update our union function to a workable set of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = [i for i in range(n)]\n",
    "\n",
    "def find(a):\n",
    "    while root[a] != a:\n",
    "        a = root[a]\n",
    "    return a\n",
    "\n",
    "def union(a, b):\n",
    "    #Find the root nodes for the components that contain  nodes a and b\n",
    "    a, b = find(a), find(b)\n",
    "    #Return early if they're already part of the same component\n",
    "    if a == b: return\n",
    "    #Connect these components\n",
    "    root[b] = a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a working disjoint set. However we can introduce a couple other things to this code, not only to optimize the time complexity significantly, but also to garner more data about a given graph than just the root array.\n",
    "\n",
    "The most unequivocal improvement to this code is *path compression*. Path compression is how the find() and union() function's time complexities optimize the most, and there's no drawback even in amount to type, so there's no reason not to include it in every disjoint set. The idea is that, for any node a, we never care about any root node in its tree (root[a], root[ root[a]], etc.) except the very top root node x, where root[x] == x. Therefore, if we ever call find(a), we might as well change root[a] to be x itself, so that we don't have to iterate up the entire height of the tree to find out that the flag node for a is x. This has cascading impacts, since then any child node of node a will travel that much shorter of a path to find root node x, before setting its own root[b] to x. Path compression changes find(a) to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(a):\n",
    "    while root[root[a]] != root[a]:\n",
    "        root[a] = root[root[a]]\n",
    "    return root[a]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look more confusing but it means that every time find(a) is called, the height of the tree is being trimmed to the minimum height of 2, where every node points directly to its flag node. This is the find() function done.\n",
    "\n",
    "A worst-case scenario that this accounts for significantly would be a graph that is essentially a linked list. Imagine that every node gets linked directly to its parent node. So root[a] == b, root[b] == c, root[c] == d... root[y] = x. Now in order to find out what component a node belongs to (for example to find out that node a belongs to component x), this is potentially an O(n) operation, to iteratively call root[a], root[ root[a]], and so-on. With path compression, this process shrinks to anywhere between logarithmic and constant time, depending on how many times find(a) is called compared to the amount of edgesin the graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is room for another significant optimization, when union(a, b) sets root[b] = a. Since we could set root[b] = a, or root[a] = b, we may as well make this choice intelligently. If we think of these root components in the root[] array as trees, that we're building with union(), and trimming and searching with find(), we can make sure that this tree is height-balanced. This means that there's no \"linked list\" worst-case scenario mentioned above, where the heigh of the tree is the number of nodes in the tree. The height of a height-balanced tree is always O(logn) where n is the height of the tree. Here, we do that by choosing whether to set root[b] = a, or root[a] = b, depending on which would displace less nodes. For this we keep track of a size array, as well as a root array. Then, when we update size[a] or size[b] to consume the other tree's size, when we change root[b] or root[a] respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "#Each node starts out as its own components, with a size of 1 (itself)\n",
    "root = [i for i in range(n)]\n",
    "size = [1 for i in range(n)]\n",
    "def find(a):\n",
    "    while root[root[a]] != root[a]:\n",
    "        root[a] = root[root[a]]\n",
    "    return root[a]\n",
    "def union(a, b):\n",
    "    a, b = find(a), find(b)\n",
    "    if a == b: return\n",
    "    #Set the root of the smaller tree to the root of the larger tree\n",
    "    if size[b] > size[a]:\n",
    "        root[a] = b\n",
    "        size[b]+=size[a]\n",
    "    else:\n",
    "        root[b] = a\n",
    "        size[a]+=size[b]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both of these optimizations, the time complexity is essentially constant. Not only can we find out of two nodes are part of the same connected component, but we can immediately find how many nodes are in a given component, by looking at size[x] for a given root node.\n",
    "\n",
    "The only other thing to mention is that components can be compared by their size (number of nodes in the component) or their rank (the maximum height of the tree). Both lead to the same time complexity, for find() and union(), which is O(α(n)), the inverse-ackermann function of n, which can safely be called constant time for any concievable number n.\n",
    "\n",
    "With this understanding, one can fully utilize disjoint sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "https://cp-algorithms.com/data_structures/segment_tree.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
