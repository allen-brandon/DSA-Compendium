{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjoint Set\n",
    "\n",
    "Please cite this if you referenced this article, and share with your friends if you found this helpful!\n",
    "\n",
    "Written by Brandon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Disjoint Set, often called Union Find or DSU, is a data structure used to find information about the connected components of a graph. Once constructed, one can use it to find all information about disconnected components in near-constant time.\n",
    "\n",
    "##### 1. An exact quickhand template\n",
    "\n",
    "        > If you are looking for quick code to copy-paste or analyze, go to the Template.\n",
    "\n",
    "\n",
    "##### 2. Notes on the nuances of this topic\n",
    "\n",
    "        > If you are looking to better an existing understanding, go to the Notes.\n",
    "\n",
    "\n",
    "##### 3. A guide to this topic, with examples.\n",
    "\n",
    "        > If you are looking to learn about this topic from a place of little understanding, go to the Guide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick access to code.\n",
    "\n",
    "* Copy inner code if class declaration isn't needed. Redefine n as number of nodes\n",
    "\n",
    "* Use desired template to find information about connected components of a graph\n",
    "\n",
    "Time complexity refers to the amortized time complexity of both union and find functions. Further explanation in second section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison by size\n",
    "#Time complexity: O(α(n))\n",
    "\n",
    "class dsu:\n",
    "    n = 10 #<< Delete this line\n",
    "    root, size = list(range(n)), [1]*n\n",
    "    def find(a):\n",
    "        while root[root[a]] != root[a]: root[a] = root[root[a]]\n",
    "        return root[a]\n",
    "    def union(a, b):\n",
    "        a, b = find(a), find(b)\n",
    "        if a == b: return\n",
    "        if size[b] > size[a]:\n",
    "            size[b] += size[a]\n",
    "            root[a] = b\n",
    "        else:\n",
    "            size[a] += size[b]\n",
    "            root[b] = a\n",
    "\n",
    "#Comparison by rank\n",
    "#Time complexity: O(α(n))\n",
    "\n",
    "class dsu:\n",
    "    n = 10 #<< Delete this line\n",
    "    root, rank = list(range(n)), [0]*n\n",
    "    def find(a):\n",
    "        while root[root[a]] != root[a]: root[a] = root[root[a]]\n",
    "        return root[a]\n",
    "    def union(a, b):\n",
    "        a, b = find(a), find(b)\n",
    "        if a == b: return\n",
    "        if rank[a] > rank[b]:\n",
    "            root[a] = b\n",
    "        elif rank[b] > rank[a]:\n",
    "            root[b] = a\n",
    "        else:\n",
    "            root[b] = a\n",
    "            rank[a]+=1\n",
    "\n",
    "#No height control\n",
    "#Time complexity: O(log2+f/n(n))\n",
    "\n",
    "class dsu:\n",
    "    n = 10 #<< Delete this line\n",
    "    root = list(range(n))\n",
    "    def find(a):\n",
    "        while root[root[a]] != root[a]: root[a] = root[root[a]]\n",
    "        return root[a]\n",
    "    def union(a, b):\n",
    "        a, b = find(a), find(b)\n",
    "        root[b] = a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Disjoint Sets are intimidating at first. But they're a particularly easy structure to work with once you understand them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to understanding and being comfortable with disjoint sets is being comfortable with representing a tree structure with an array.\n",
    "\n",
    "There are multiple ways to do this. For example, heaps are balanced binary trees, where index 0 always represents the root.\n",
    "\n",
    "In the case of a disjoint set's root array, we have some specific constraints. Namely, the array represents a \"forest\", e.g. multiple trees, rather than just 1 tree. We're always doing one of two things when we edit this array: Combining two trees into a larger tree, or setting a node's parent to be its grandparent (if we're implementing path compression). An effective way to represent this structure is to treat the value at each index i as representing another index j, somewhere between 0 and n, meaning that node j is node i's parent. This gives rise to an imagined tree (or series of trees throughout the root array), which correspond to components in the graph (each index in a given tree being the values of nodes in that component). That's the simple essense of a disjoint set.\n",
    "\n",
    "With data structures and algorithms that demand an abstract conceptualization (here a series of trees being represented with a single array), a lack of acuity leads a simple system to appear much more unweildly than it actually is. The unequivocal remedy is to work with this structure until it becomes routine. Another source of this mind-fog around a topic often results from vague confusion around unanswered questions, that often even remain too vague in one's mind to even be asked.\n",
    "\n",
    "Here is an FAQ to a couple of those questions:\n",
    "\n",
    "* What if the graph is directed?\n",
    "    Disjoint sets describe components of a graph, that are connected at all. This matches up perfectly with describing nodes and components of undirected graphs. Interpolating this logic to describe a directed graph is dependent on the context. Disjoint sets are used to find connected components in an undirected graph, and tarjan's algorithm is used to find *strongly* connected components, in directional and undirectional graphs. Strongly connected components contain nodes that are not only connected to each other, but form a cycle. Tarjan's algorithm is often used to approximate the \"can node A be reached by node B?\" question that disjoint sets answer to directed graphs. This is similar to the relationship Dijkstra's algorithm has to BFS, where dijkstra's interpolants the shortest path problem from unweighted to weighted graphs, though both BFS and Dijkstra's algorithm can have uses in weighted and unweighted graphs each. Sinmilarly, both Tarjan's algorithm and Disjoint sets can each be used to garner information about directed and undirected graphs.\n",
    "\n",
    "* My disjoint set is giving wrong answers?\n",
    "    You *always* want to call find(a) to find the root node of a, rather than root[a]. Otherwise, node a might point to an outdated root-node, that itself points to the actual root node (whether directly or indirectly). Even when a disjoint set is fully constructed, there can still be these outdated root-pointers, which are accounted for when find() is called. This is a very common source of error, when the disjoint set isn't working as intented.\n",
    "\n",
    "* What if a node in the array points past the end of the array? (e.g. [0,1,6,3,4])\n",
    "    Answer: This will never happen. Every node is initially pointing to itself. root[i] == i, meaning that node i is the root of its own 1-node tree. The only operation that can change a given root[i] is setting it to another root[j]. This means that no element will ever be set to anything outside of the range 0 to n-1.\n",
    "\n",
    "* What about a root array where two indices point to each other? (e.g. [0,1,5,3,4,2])\n",
    "    Answer: This could never happen, because the union(x, y) function will not change anything in the root array, if x and y are already in the same component. This means that cycles will never form (except when an index points to itself, which is specifically accounted for as meaning that the node is the root of its tree).\n",
    "\n",
    "It's always important to know the time complexity for a given operation. Below For those who are truly curious about the time complexity of the find() and union() operations of non-optimized disjoint set code. The time complexity described is that of the find() function, as the union() function is constant time, other than its calls to the find() function. This does not describe the space complexity, or the time complexity of initializing the root/size arrays, both of which are O(n) (to initialize one or two arrays of size n). Height control here refers to both size and rank comparison, as their time complexities are the same.\n",
    "\n",
    "The time complexities are as follows:\n",
    "\n",
    "* Path compression and height control:\n",
    "    Time complexity: O(α(n))\n",
    "    α here represents the inverse-Ackerman function. The logic of the function is unimportant. What is important is that the Ackerman function diverges extremely quickly. Likewise, the inverse-Ackerman function converges extremely quickly to a constant. Almost unfathomably quickly. It's difficult to conceive of input parameters that would cause the inverse-Ackerman function to output a coefficient greater than 4. In other words, O(α(n)) is *at worst* O(4n), which is completely indestinguishable from constant time. For this reason, one can treat disjoint set operations as unequivocally linear time, though technically it is not.\n",
    "\n",
    "* Path compression and no height control:\n",
    "    Time complexity: O(1+log2+f/n(n)) where f is the number of times \"find\" has been called\n",
    "    This may look confusing at first but it logically makes sense under scrutiny. Each time find is called, the base of the logarithm that describes the time complexity (e.g. logx(n)) increases. The first call to find could be linear in time, and once call has been called many times, find will quickly approach logn(n) time, and be constant.\n",
    "\n",
    "* Height control and no path compression:\n",
    "    Time complexity: O(logn)\n",
    "    Height control, either by rank or by size, ensures that the tree represented by the root array is height-balanced. This ensures that the height of the tree is proportional to log(n). This means that each find() operation performs logn operations when it scales the height of the tree from a given node to the root node of that tree.\n",
    "\n",
    "* No path compression or height control:\n",
    "    Time complexity: O(n)\n",
    "    In a worst-case scenario, a tree forms with a height of n, meaning that find() is an operation with linear time complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guide notes:\n",
    "Space complexity\n",
    "Compare recursive vs. iterative find function\n",
    "Time complexity\n",
    "Path compression\n",
    "Height control\n",
    "Always call find(a), not root[a], when using disjoint set to avoid non-updated pointers\n",
    "When to use flood fill vs. disjoint sets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "\n",
    "Below is a detailed explanation of exactly what disjoint sets are, as well as its related terms. This is meant to acquaint you with tisjoint sets, if you're not familiar with them, and walk through the reasoning behind each piece of the code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two extremely common questions that get asked about graphs:\n",
    "\n",
    "* What is the shortest path between two nodes?\n",
    "* Are two nodes reachable from one another?\n",
    "\n",
    "Disjoint sets are what we use to find the answer to the second of those questions (the answer to the first being BFS/Dijkstra's algorithm). For this reason they're among the most commonly used approaches for answering questions about graphs. Among other things, disjoint sets can be used to ansewr:\n",
    "\n",
    "1. Do two nodes belong to the same component?\n",
    "2. How many components are in a graph?\n",
    "3. How many nodes belong to a given component in a graph?\n",
    "\n",
    "Disjoint sets are almost always used to describe the \"components\" of a graph. In order to talk about disjoint sets further, we need to define what a \"component\" is, along with a couple of other important terms.\n",
    "\n",
    "* Component:\n",
    "    A group of nodes that are all connected to one another, directly or indirectly.\n",
    "\n",
    "* Direct vs. Indirect connection:\n",
    "    Two nodes are directly connected if they share a direct edge. Two nodes are indirectly connected if they share edges with other directly or indirectly connected nodes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a disjoint set from the ground up.\n",
    "\n",
    "Take the following graph, in the form of an adjacency list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 5 nodes: 0, 1, 2, 3, and 4\n",
    "n = 5\n",
    "#The graph is bidirectional;\n",
    "#If adj[i] contains j, then adj[j] contains i\n",
    "adj = {0:[1,2], 1:[0], 2:[0], 3:[4], 4:[3]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that node 0 is connected to nodes 1 and 2 (and vice versa). We can also see that 3 and 4 are connected to each other.\n",
    "\n",
    "Even though node 1 and node 2 aren't directly connected, we can see that they're indirectly connected through node 0. So nodes 0, 1 and 2 are all reachable from one another. But none of them can reach nodes 3 or 4. So there are two different islands, or components, in the graph. There's nodes 0, 1 and 2, and then nodes 3 and 4. We can reason through this, but how can we find this out about much larger, more complicated graphs? This is what a disjoint set is for.\n",
    "\n",
    "Before going further into its uses, let's go over the anatomy and mechanism of a disjoint set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root array\n",
    "root = [i for i in range(n)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root array, sometimes called the parent array, is the central data structure. For every node, root[i] is the root node of the ith node. This represents that nodes i, and root[i] are connected. For example, if root[1] is 0, and root[2] is 0, then both 1 and 2 are connected to root 0 (and each other). Then, if we every want to check if two nodes are connected, we can check to see if their root is the same. If root[1] is 0, and root[2] is 0, then we know they're connected to the same node, and therefore root 1 and root 2 are connected.\n",
    "\n",
    "Initially, each index in the root array points to itself. root[0] == 0, root[1] == 1, etc. This represents the initial state, that each node exists in its own component, before any edges have been introduced. The next step is to create a way to populate and access the root array. Let's start with a simplified version of union(a, b), which is how we introduce an edge between a and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#represent an edge between a and b\n",
    "def union(a, b):\n",
    "    root[b] = a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a way to connect two nodes. If we call this union on each edge, we can create an initial root array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in adj:\n",
    "    for b in adj[a]:\n",
    "        if b > a:\n",
    "            union(a, b)\n",
    "#Root:\n",
    "#[0, 0, 0, 3, 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are two groups of nodes. The nodes connected to node 0, and nodes connected to node 3. Now it appears that we have two distinct components in this graph.\n",
    "\n",
    "There are a couple things to notice about this function. The order is arbitrary here. We could just as easily have said \"root[a] = b.\" We'll return to that later. \n",
    "\n",
    "Another thing to notice about this function is that it can create trees with a large depth. Say we change our graph above slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 connects 0 and 2, instead of 0 connecting 1 and 2\n",
    "adj = {0:[1], 1:[0, 2], 2:[1], 3:[4], 4:[3]}\n",
    "#Reset root\n",
    "root = [i for i in range(n)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now 0 and 2 are connected to 1, instead of 1 and 2 being connected to 0. If we again call union, the root array will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in adj:\n",
    "    for b in adj[a]:\n",
    "        if b > a:\n",
    "            union(a, b)\n",
    "#Root:\n",
    "#[0, 0, 1, 3, 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now node 2 leads to node 1, which leads to node 0, which leads to itself, as it's the root node of its tree of connected nodes. This isn't what we want. We want every node to point to its original root node, rather than just the node above it in the tree. This is where we need a find(a) function, in order to find and update the original root node for node a.\n",
    "\n",
    "We always want to use find(a), rather than root[a], regardless of the context. Let's say root[a] gets set to node c, but then root[c] gets changed. Even if we initially used find(a) and find(c) to set root[a] to c, now we need to call find(a) again to set root[a] to find d, since node c now points to node d instead of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fina(a): find the flag node for node a\n",
    "def find(a):\n",
    "    while root[a] != a:\n",
    "        a = root[a]\n",
    "    return a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also potentially didn't want to change anything when we call union(a, b). For example if root[a] is b, we don't want to change root[b] to be a (this would arise for example if we blindly iterated through the adjacency list of a bidirectional graph, and accounted for each edge twice). If we do this, each node is each other's root. And if we look for the root \"flag-node\" for a given node by repeatedly looking at root[a] then root[ root[a]]... etc. Then we'll enter an infinite cycle. This is solved by returning from the function early if the nodes are already connected. Now we can update our union function to a workable set of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = [i for i in range(n)]\n",
    "\n",
    "def find(a):\n",
    "    while root[a] != a:\n",
    "        a = root[a]\n",
    "    return a\n",
    "\n",
    "def union(a, b):\n",
    "    #Find the root nodes for the components that contain  nodes a and b\n",
    "    a, b = find(a), find(b)\n",
    "    #Return early if they're already part of the same component\n",
    "    if a == b: return\n",
    "    #Connect these components\n",
    "    root[b] = a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a working disjoint set. However we can introduce a couple other things to this code, not only to optimize the time complexity significantly, but also to garner more data about a given graph than just the root array.\n",
    "\n",
    "The most unequivocal improvement to this code is *path compression*. Path compression is how the find() and union() function's time complexities optimize the most, and there's no drawback even in amount to type, so there's no reason not to include it in every disjoint set. The idea is that, for any node a, we never care about any root node in its tree (root[a], root[ root[a]], etc.) except the very top root node x, where root[x] == x. Therefore, if we ever call find(a), we might as well change root[a] to be x itself, so that we don't have to iterate up the entire height of the tree to find out that the flag node for a is x. This has cascading impacts, since then any child node of node a will travel that much shorter of a path to find root node x, before setting its own root[b] to x. Path compression changes find(a) to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(a):\n",
    "    while root[root[a]] != root[a]:\n",
    "        root[a] = root[root[a]]\n",
    "    return root[a]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look more confusing but it means that every time find(a) is called, the height of the tree is being trimmed to the minimum height of 2, where every node points directly to its flag node. This is the find() function done.\n",
    "\n",
    "A worst-case scenario that this accounts for significantly would be a graph that is essentially a linked list. Imagine that every node gets linked directly to its parent node. So root[a] == b, root[b] == c, root[c] == d... root[y] = x. Now in order to find out what component a node belongs to (for example to find out that node a belongs to component x), this is potentially an O(n) operation, to iteratively call root[a], root[ root[a]], and so-on. With path compression, this process shrinks to anywhere between logarithmic and constant time, depending on how many times find(a) is called compared to the amount of edgesin the graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is room for another significant optimization, when union(a, b) sets root[b] = a. Since we could set root[b] = a, or root[a] = b, we may as well make this choice intelligently. If we think of these root components in the root[] array as trees, that we're building with union(), and trimming and searching with find(), we can make sure that this tree is height-balanced. This means that there's no \"linked list\" worst-case scenario mentioned above, where the heigh of the tree is the number of nodes in the tree. The height of a height-balanced tree is always O(logn) where n is the height of the tree. Here, we do that by choosing whether to set root[b] = a, or root[a] = b, depending on which would displace less nodes. For this we keep track of a size array, as well as a root array. Then, when we update size[a] or size[b] to consume the other tree's size, when we change root[b] or root[a] respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each node starts out as its own components, with a size of 1 (itself)\n",
    "root = [i for i in range(n)]\n",
    "size = [1 for i in range(n)]\n",
    "def find(a):\n",
    "    while root[root[a]] != root[a]:\n",
    "        root[a] = root[root[a]]\n",
    "    return root[a]\n",
    "def union(a, b):\n",
    "    a, b = find(a), find(b)\n",
    "    if a == b: return\n",
    "    #Set the root of the smaller tree to the root of the larger tree\n",
    "    if size[b] > size[a]:\n",
    "        root[a] = b\n",
    "        size[b]+=size[a]\n",
    "    else:\n",
    "        root[b] = a\n",
    "        size[a]+=size[b]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both of these optimizations, the time complexity is essentially constant. Not only can we find out of two nodes are part of the same connected component, but we can immediately find how many nodes are in a given component, by looking at size[x] for a given root node.\n",
    "\n",
    "The only other thing to mention is that components can be compared by their size (number of nodes in the component) or their rank (the maximum height of the tree). Both lead to the same time complexity, for find() and union(), which is O(α(n)), the inverse-ackermann function of n, which can safely be called constant time for any concievable number n.\n",
    "\n",
    "With this understanding, one can fully utilize disjoint sets!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
